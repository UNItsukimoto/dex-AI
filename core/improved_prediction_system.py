#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
äºˆæ¸¬ç²¾åº¦50%ä»¥ä¸Šã‚’å…¨æœŸé–“ã§é”æˆã™ã‚‹æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ 
é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºã‚’å«ã‚€
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import json
import os
from pathlib import Path
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.svm import SVR
import xgboost as xgb
import lightgbm as lgb
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import mutual_info_regression, SelectKBest
from sklearn.model_selection import TimeSeriesSplit
from scipy import signal
from scipy.stats import kurtosis, skew
import warnings
warnings.filterwarnings('ignore')

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ImprovedPredictionSystem:
    """æ”¹å–„ã•ã‚ŒãŸäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - 50%ä»¥ä¸Šã®ç²¾åº¦ã‚’ç›®æŒ‡ã™"""
    
    def __init__(self):
        self.data_dir = Path("data/historical")
        self.results_dir = Path("results/improved_system")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        self.results = {}
        
    def load_period_data(self, period_name):
        """æœŸé–“ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        filepath = self.data_dir / f"BTC_1h_{period_name}.csv"
        
        if not filepath.exists():
            alt_filepath = Path("data/processed/btc_features.csv")
            if alt_filepath.exists() and period_name == "current":
                filepath = alt_filepath
            else:
                logger.warning(f"Data file not found: {filepath}")
                return None
            
        try:
            df = pd.read_csv(filepath, index_col=0)
            df.index = pd.to_datetime(df.index)
            
            # åŸºæœ¬çš„ãªOHLCVåˆ—ã‚’ç¢ºä¿
            if 'close' in df.columns:
                # å¯èƒ½ãªé™ã‚Šå¤šãã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                price_cols = []
                for col in ['open', 'high', 'low', 'close', 'volume']:
                    if col in df.columns:
                        price_cols.append(col)
                
                df = df[price_cols]
                
                # OHLCãŒä¸å®Œå…¨ãªå ´åˆã¯è£œå®Œ
                if 'open' not in df.columns:
                    df['open'] = df['close'].shift(1)
                if 'high' not in df.columns:
                    df['high'] = df['close']
                if 'low' not in df.columns:
                    df['low'] = df['close']
                if 'volume' not in df.columns:
                    df['volume'] = 1000000  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                
                # æ•°å€¤å¤‰æ›
                for col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                
                df = df.dropna()
                logger.info(f"Loaded {period_name}: {len(df)} records")
                return df
            else:
                logger.error(f"No price data in {period_name}")
                return None
                
        except Exception as e:
            logger.error(f"Error loading {period_name}: {e}")
            return None
    
    def detect_market_regime(self, df):
        """é©å¿œçš„å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ ã®æ¤œå‡º"""
        close = df['close']
        data_len = len(df)
        
        # ã‚ˆã‚Šä¿å®ˆçš„ãªé©å¿œçš„æœŸé–“è¨­å®š
        short_period = min(10, max(3, data_len // 12))
        long_period = min(30, max(5, data_len // 8))
        vol_period = min(20, max(5, data_len // 10))
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
        if short_period < long_period and long_period > 0:
            ma_short = close.rolling(short_period).mean()
            ma_long = close.rolling(long_period).mean()
            trend_strength = (ma_short - ma_long) / (ma_long + 1e-8)
            df['trend_strength'] = trend_strength
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘
            df['trend_direction'] = np.where(trend_strength > 0.01, 1,  # ä¸Šæ˜‡
                                            np.where(trend_strength < -0.01, -1, 0))  # ä¸‹é™ / æ¨ªã°ã„
        else:
            df['trend_strength'] = 0
            df['trend_direction'] = 0
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        if vol_period > 0:
            volatility = close.pct_change().rolling(vol_period).std()
            df['volatility_regime'] = volatility
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
            vol_median = volatility.median()
            df['vol_regime'] = np.where(volatility > vol_median * 1.2, 1, 0)  # é«˜ãƒœãƒ© / ä½ãƒœãƒ©
        else:
            df['volatility_regime'] = close.pct_change().std()
            df['vol_regime'] = 0
        
        return df
    
    def create_advanced_features(self, df):
        """ãƒ‡ãƒ¼ã‚¿é‡ã«é©å¿œã—ãŸé«˜åº¦ãªç‰¹å¾´é‡ã®ä½œæˆ"""
        logger.info(f"Creating adaptive features for {len(df)} data points...")
        
        # ãƒ‡ãƒ¼ã‚¿é‡ã«åŸºã¥ãé©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚ˆã‚Šä¿å®ˆçš„ã«ï¼‰
        data_len = len(df)
        max_period = min(50, data_len // 8)  # ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
        
        # åŸºæœ¬ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        open_price = df['open']
        high = df['high']
        low = df['low']
        close = df['close']
        volume = df['volume']
        
        # === 1. åŸºæœ¬çš„ãªä¾¡æ ¼ç‰¹å¾´é‡ ===
        df['returns'] = close.pct_change()
        df['log_returns'] = np.log(close / close.shift(1))
        df['price_change'] = close - open_price
        df['price_range'] = high - low
        df['body_ratio'] = (close - open_price) / (high - low + 1e-8)
        
        # === 2. é©å¿œçš„ç§»å‹•å¹³å‡ç³» ===
        periods = [p for p in [5, 10, 20, 30] if p <= max_period and p <= data_len // 10]
        if not periods:  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            periods = [min(5, data_len // 10)]
        for period in periods:
            if period > 0:
                ma = close.rolling(period).mean()
                df[f'ma_{period}'] = ma
                df[f'ma_ratio_{period}'] = close / (ma + 1e-8)
                df[f'ma_distance_{period}'] = (close - ma) / (close + 1e-8)
        
        # === 3. é©å¿œçš„æŒ‡æ•°ç§»å‹•å¹³å‡ã¨MACD ===
        ema_fast = min(8, max_period // 2)
        ema_slow = min(21, max_period)
        if ema_fast < ema_slow:
            ema_f = close.ewm(span=ema_fast).mean()
            ema_s = close.ewm(span=ema_slow).mean()
            df['macd'] = ema_f - ema_s
            df['macd_signal'] = df['macd'].ewm(span=min(6, max_period // 3)).mean()
            df['macd_histogram'] = df['macd'] - df['macd_signal']
        
        # === 4. é©å¿œçš„RSI ===
        rsi_periods = [p for p in [7, 14] if p <= max_period]
        for period in rsi_periods:
            delta = close.diff()
            gain = (delta.where(delta > 0, 0)).rolling(period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(period).mean()
            rs = gain / loss
            df[f'rsi_{period}'] = 100 - (100 / (1 + rs))
        
        # === 5. é©å¿œçš„ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ ===
        bb_periods = [p for p in [10, 15] if p <= max_period]
        for period in bb_periods:
            ma = close.rolling(period).mean()
            std = close.rolling(period).std()
            df[f'bb_upper_{period}'] = ma + (2 * std)
            df[f'bb_lower_{period}'] = ma - (2 * std)
            df[f'bb_position_{period}'] = (close - df[f'bb_lower_{period}']) / (df[f'bb_upper_{period}'] - df[f'bb_lower_{period}'])
            df[f'bb_width_{period}'] = (df[f'bb_upper_{period}'] - df[f'bb_lower_{period}']) / ma
        
        # === 6. é©å¿œçš„ATR ===
        tr = pd.concat([
            high - low,
            abs(high - close.shift(1)),
            abs(low - close.shift(1))
        ], axis=1).max(axis=1)
        atr_period = min(10, max_period)
        df[f'atr_{atr_period}'] = tr.rolling(atr_period).mean()
        df['atr_ratio'] = df['price_range'] / (df[f'atr_{atr_period}'] + 1e-8)
        
        # === 7. é©å¿œçš„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ ===
        vol_periods = [p for p in [3, 5, 7, 10] if p <= max_period]
        for period in vol_periods:
            df[f'volatility_{period}'] = df['returns'].rolling(period).std()
            # é•·æœŸå¹³å‡ã¨ã®æ¯”è¼ƒã¯çŸ­æœŸé–“ã§ä»£æ›¿
            if period <= max_period // 2:
                df[f'vol_ratio_{period}'] = df[f'volatility_{period}'] / df[f'volatility_{period}'].rolling(period * 2).mean()
        
        # === 8. é©å¿œçš„ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç‰¹å¾´é‡ ===
        momentum_periods = [p for p in [1, 2, 3, 5] if p <= max_period // 2]
        for period in momentum_periods:
            df[f'momentum_{period}'] = close / close.shift(period) - 1
            if period > 1:
                df[f'momentum_change_{period}'] = df[f'momentum_{period}'] - df[f'momentum_{period}'].shift(1)
        
        # === 9. é©å¿œçš„ä¾¡æ ¼ä½ç½®ç‰¹å¾´é‡ ===
        position_periods = [p for p in [5, 7, 10] if p <= max_period]
        for period in position_periods:
            rolling_max = close.rolling(period).max()
            rolling_min = close.rolling(period).min()
            df[f'price_position_{period}'] = (close - rolling_min) / (rolling_max - rolling_min + 1e-8)
            df[f'distance_from_high_{period}'] = (rolling_max - close) / (rolling_max + 1e-8)
            df[f'distance_from_low_{period}'] = (close - rolling_min) / (rolling_min + 1e-8)
        
        # === 10. é©å¿œçš„å‡ºæ¥é«˜ç‰¹å¾´é‡ ===
        vol_ma_periods = [p for p in [3, 5, 7] if p <= max_period // 2]
        for period in vol_ma_periods:
            df[f'volume_ma_{period}'] = volume.rolling(period).mean()
            df[f'volume_ratio_{period}'] = volume / (df[f'volume_ma_{period}'] + 1e-8)
            if f'momentum_{period}' in df.columns:
                df[f'volume_price_trend_{period}'] = df[f'volume_ratio_{period}'] * df[f'momentum_{period}']
        
        # === 11. æ™‚é–“çš„ç‰¹å¾´é‡ ===
        df['hour'] = df.index.hour
        df['day_of_week'] = df.index.dayofweek
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
        
        # === 12. é©å¿œçš„çµ±è¨ˆçš„ç‰¹å¾´é‡ ===
        stat_periods = [p for p in [5, 8] if p <= max_period // 2]
        for period in stat_periods:
            returns_window = df['returns'].rolling(period)
            df[f'skewness_{period}'] = returns_window.skew()
            df[f'kurtosis_{period}'] = returns_window.kurt()
        
        # === 13. ç°¡ç•¥åŒ–ãƒ•ãƒ¼ãƒªã‚¨ç‰¹å¾´é‡ ===
        if data_len > 30:
            # çŸ­æœŸå‘¨æœŸæ€§ã®æ¤œå‡ºï¼ˆç°¡ç•¥ç‰ˆï¼‰
            window = min(12, max_period)
            if data_len > window * 2:
                price_segment = close.iloc[-window*2:].values
                if len(price_segment) > 4:
                    try:
                        fft = np.fft.fft(price_segment)
                        power_spectrum = np.abs(fft)
                        dominant_freq_idx = np.argmax(power_spectrum[1:len(power_spectrum)//2]) + 1
                        df.loc[df.index[-len(price_segment):], 'fft_dominant'] = dominant_freq_idx
                        df.loc[df.index[-len(price_segment):], 'fft_power'] = power_spectrum[dominant_freq_idx]
                    except:
                        pass
        
        # === 14. é©å¿œçš„ãƒ©ã‚°ç‰¹å¾´é‡ ===
        max_lag = min(3, max_period // 3)
        for lag in range(1, max_lag + 1):
            df[f'returns_lag_{lag}'] = df['returns'].shift(lag)
            # åŸºæœ¬å‡ºæ¥é«˜æ¯”ã®ãƒ©ã‚°
            if 'volume_ratio_3' in df.columns:
                df[f'volume_lag_{lag}'] = df['volume_ratio_3'].shift(lag)
        
        # === 15. å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ ç‰¹å¾´é‡ ===
        df = self.detect_market_regime(df)
        
        # === 16. åŸºæœ¬çš„é«˜æ¬¡ç‰¹å¾´é‡ ===
        df['price_acceleration'] = df['returns'].diff()
        
        # === 17. ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ï¼ˆé¸æŠçš„ï¼‰ ===
        # æœ€ã‚‚åŸºæœ¬çš„ãªå‡ºæ¥é«˜æ¯”ã¨ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã®ç›¸äº’ä½œç”¨
        basic_vol_col = None
        basic_momentum_col = None
        
        for col in df.columns:
            if 'volume_ratio_' in col and basic_vol_col is None:
                basic_vol_col = col
            if 'momentum_' in col and basic_momentum_col is None:
                basic_momentum_col = col
        
        if basic_vol_col and basic_momentum_col:
            df['volume_price_correlation'] = df[basic_vol_col] * df[basic_momentum_col]
        
        if 'volatility_3' in df.columns and basic_momentum_col:
            df['volatility_momentum'] = df['volatility_3'] * df[basic_momentum_col]
        
        if 'trend_strength' in df.columns and 'volatility_3' in df.columns:
            df['trend_strength_vol'] = df['trend_strength'] * df['volatility_3']
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
        df['target'] = df['returns'].shift(-1)
        df['target_direction'] = np.sign(df['target'])
        
        # ã‚ˆã‚Šä¿å®ˆçš„ãªæ¬ æå€¤å‡¦ç†
        # ã¾ãšå‰æ–¹è£œå®Œã‚’è©¦è¡Œ
        df = df.fillna(method='ffill')
        # æ®‹ã£ãŸæ¬ æå€¤ã‚’å¾Œæ–¹è£œå®Œ
        df = df.fillna(method='bfill')
        # ã¾ã æ®‹ã£ãŸæ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹
        df = df.fillna(0)
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒNaNã®è¡Œã®ã¿å‰Šé™¤
        df = df.dropna(subset=['target'])
        
        feature_count = len([col for col in df.columns if col not in ['open', 'high', 'low', 'close', 'volume', 'target', 'target_direction']])
        logger.info(f"Created {feature_count} adaptive features for {len(df)} data points")
        
        return df
    
    def select_best_features(self, X, y, k=50):
        """æœ€è‰¯ã®ç‰¹å¾´é‡ã‚’é¸æŠ"""
        logger.info(f"Selecting best {k} features from {X.shape[1]} total features")
        
        # ç›¸äº’æƒ…å ±é‡ã«ã‚ˆã‚‹ç‰¹å¾´é‡é¸æŠ
        selector = SelectKBest(score_func=mutual_info_regression, k=min(k, X.shape[1]))
        X_selected = selector.fit_transform(X, y)
        
        # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        selected_features = selector.get_support(indices=True)
        
        logger.info(f"Selected {len(selected_features)} features")
        
        return X_selected, selected_features
    
    def create_advanced_ensemble(self):
        """é«˜åº¦ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ"""
        models = {
            # æœ¨ç³»ãƒ¢ãƒ‡ãƒ«
            'rf': RandomForestRegressor(
                n_estimators=100, max_depth=8, min_samples_split=5,
                min_samples_leaf=2, random_state=42, n_jobs=-1
            ),
            'extra_trees': ExtraTreesRegressor(
                n_estimators=100, max_depth=8, min_samples_split=5,
                min_samples_leaf=2, random_state=42, n_jobs=-1
            ),
            'gb': GradientBoostingRegressor(
                n_estimators=100, max_depth=6, learning_rate=0.1,
                subsample=0.8, random_state=42
            ),
            
            # ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°
            'xgb': xgb.XGBRegressor(
                n_estimators=100, max_depth=6, learning_rate=0.1,
                subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1
            ),
            'lgb': lgb.LGBMRegressor(
                n_estimators=100, max_depth=6, learning_rate=0.1,
                subsample=0.8, colsample_bytree=0.8, random_state=42,
                n_jobs=-1, verbose=-1
            ),
            
            # ç·šå½¢ãƒ¢ãƒ‡ãƒ«
            'ridge': Ridge(alpha=1.0),
            'lasso': Lasso(alpha=0.1),
            'elastic': ElasticNet(alpha=0.1, l1_ratio=0.5),
            
            # SVR
            'svr_rbf': SVR(kernel='rbf', C=1.0, epsilon=0.1),
            'svr_linear': SVR(kernel='linear', C=1.0, epsilon=0.1)
        }
        
        return models
    
    def train_stacked_ensemble(self, X_train, y_train, X_val, y_val):
        """ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®è¨“ç·´"""
        logger.info("Training stacked ensemble...")
        
        # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
        base_models = self.create_advanced_ensemble()
        
        # ãƒ¬ãƒ™ãƒ«1ã®äºˆæ¸¬ã‚’ç”Ÿæˆ
        level1_features = []
        trained_models = {}
        
        # äº¤å·®æ¤œè¨¼ã§å„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
        tscv = TimeSeriesSplit(n_splits=3)
        
        for name, model in base_models.items():
            logger.info(f"Training base model: {name}")
            
            # äº¤å·®æ¤œè¨¼ã«ã‚ˆã‚‹äºˆæ¸¬
            cv_predictions = np.zeros(len(X_train))
            
            for train_idx, val_idx in tscv.split(X_train):
                X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]
                y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]
                
                model_copy = base_models[name]
                model_copy.fit(X_fold_train, y_fold_train)
                cv_predictions[val_idx] = model_copy.predict(X_fold_val)
            
            level1_features.append(cv_predictions)
            
            # å…¨ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´
            model.fit(X_train, y_train)
            trained_models[name] = model
        
        # ãƒ¬ãƒ™ãƒ«1ç‰¹å¾´é‡
        level1_train = np.column_stack(level1_features)
        
        # ãƒ¬ãƒ™ãƒ«1ã®æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬
        level1_val_features = []
        for name, model in trained_models.items():
            pred = model.predict(X_val)
            level1_val_features.append(pred)
        
        level1_val = np.column_stack(level1_val_features)
        
        # ãƒ¬ãƒ™ãƒ«2ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ¡ã‚¿ãƒ©ãƒ¼ãƒŠãƒ¼ï¼‰
        meta_model = Ridge(alpha=0.1)
        meta_model.fit(level1_train, y_train)
        
        return trained_models, meta_model, level1_val
    
    def run_improved_backtest(self, period_name):
        """æ”¹å–„ã•ã‚ŒãŸãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        logger.info(f"\n{'='*60}")
        logger.info(f"Processing {period_name} with adaptive improved system")
        logger.info(f"{'='*60}")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = self.load_period_data(period_name)
        if df is None or len(df) < 30:
            logger.warning(f"Insufficient initial data for {period_name}: {len(df) if df is not None else 0} points")
            return None
        
        # é©å¿œçš„ç‰¹å¾´é‡ä½œæˆ
        df = self.create_advanced_features(df)
        min_required = max(20, len(df) // 10)  # é©å¿œçš„æœ€å°è¦æ±‚æ•°
        if len(df) < min_required:
            logger.warning(f"Insufficient data after feature engineering: {len(df)} < {min_required}")
            return None
        
        # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        exclude_cols = ['target', 'target_direction', 'open', 'high', 'low', 'close', 'volume']
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        
        X = df[feature_cols].values
        y = df['target'].values
        
        # æ¬ æå€¤ã¨ç„¡é™å€¤ã®å‡¦ç†
        X = np.nan_to_num(X, nan=0, posinf=1e6, neginf=-1e6)
        
        # ç‰¹å¾´é‡é¸æŠ
        X_selected, selected_indices = self.select_best_features(X, y, k=min(50, X.shape[1]))
        
        # è¨“ç·´/ãƒ†ã‚¹ãƒˆåˆ†å‰²
        split_idx = int(0.7 * len(X_selected))
        X_train, X_test = X_selected[:split_idx], X_selected[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨“ç·´
        base_models, meta_model, level1_val = self.train_stacked_ensemble(
            X_train_scaled, y_train, X_test_scaled, y_test
        )
        
        # æœ€çµ‚äºˆæ¸¬
        final_predictions = meta_model.predict(level1_val)
        
        # äºˆæ¸¬ç²¾åº¦è¨ˆç®—
        direction_accuracy = self.calculate_direction_accuracy(y_test, final_predictions)
        
        logger.info(f"Improved Direction Accuracy: {direction_accuracy:.2%}")
        
        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        test_df = df.iloc[split_idx:].copy()
        backtest_results = self._run_enhanced_backtest(test_df, final_predictions)
        
        # Buy & Hold
        buy_hold_return = (test_df['close'].iloc[-1] - test_df['close'].iloc[0]) / test_df['close'].iloc[0]
        
        # çµæœã¾ã¨ã‚
        result = {
            'period': period_name,
            'data_points': len(df),
            'features_used': len(selected_indices),
            'prediction_accuracy': direction_accuracy,
            'buy_hold_return': buy_hold_return,
            'backtest_results': backtest_results,
            'model_weights': self._calculate_model_importance(base_models, X_test_scaled, y_test)
        }
        
        return result
    
    def calculate_direction_accuracy(self, y_true, y_pred):
        """æ–¹å‘æ€§äºˆæ¸¬ç²¾åº¦ã®è¨ˆç®—"""
        true_direction = np.sign(y_true)
        pred_direction = np.sign(y_pred)
        
        # ã‚¼ãƒ­ã‚’é™¤å¤–
        mask = true_direction != 0
        if np.sum(mask) == 0:
            return 0.5
        
        true_direction = true_direction[mask]
        pred_direction = pred_direction[mask]
        
        return accuracy_score(true_direction, pred_direction)
    
    def _calculate_model_importance(self, models, X_test, y_test):
        """å„ãƒ¢ãƒ‡ãƒ«ã®é‡è¦åº¦è¨ˆç®—"""
        importance = {}
        for name, model in models.items():
            pred = model.predict(X_test)
            acc = self.calculate_direction_accuracy(y_test, pred)
            importance[name] = acc
        
        return importance
    
    def _run_enhanced_backtest(self, test_df, predictions):
        """å¼·åŒ–ã•ã‚ŒãŸãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
        strategies = {
            'Conservative': {'threshold': 0.008, 'position_size': 0.03},
            'Moderate': {'threshold': 0.005, 'position_size': 0.05},
            'Aggressive': {'threshold': 0.003, 'position_size': 0.08},
            'Ultra_Aggressive': {'threshold': 0.001, 'position_size': 0.10}
        }
        
        results = {}
        initial_capital = 100000
        
        for strategy_name, params in strategies.items():
            capital = initial_capital
            position = 0
            trades = []
            
            for i in range(min(len(predictions), len(test_df) - 1)):
                pred = predictions[i]
                price = test_df['close'].iloc[i]
                
                # ã‚ˆã‚Šç²¾å¯†ãªå–å¼•ã‚·ã‚°ãƒŠãƒ«
                signal_strength = abs(pred)
                
                if pred > params['threshold'] and position == 0 and signal_strength > params['threshold']:
                    # è²·ã„
                    position = capital * params['position_size'] / price
                    entry_price = price
                    trades.append({'type': 'buy', 'price': price, 'signal': pred})
                    
                elif (pred < -params['threshold'] and position > 0) or (position > 0 and i - len([t for t in trades if t['type'] == 'buy']) > 24):
                    # å£²ã‚Šï¼ˆã‚·ã‚°ãƒŠãƒ«ã¾ãŸã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
                    exit_price = price
                    pnl = position * (exit_price - entry_price)
                    capital += pnl
                    
                    trades.append({'type': 'sell', 'price': price, 'pnl': pnl})
                    position = 0
            
            # æœ€çµ‚æ¸…ç®—
            if position > 0:
                final_price = test_df['close'].iloc[-1]
                pnl = position * (final_price - entry_price)
                capital += pnl
            
            # çµæœè¨ˆç®—
            total_return = (capital - initial_capital) / initial_capital
            num_trades = len([t for t in trades if t['type'] == 'buy'])
            winning_trades = len([t for t in trades if t.get('pnl', 0) > 0])
            win_rate = winning_trades / num_trades if num_trades > 0 else 0
            
            results[strategy_name] = {
                'total_return': total_return,
                'num_trades': num_trades,
                'win_rate': win_rate
            }
        
        return results
    
    def run_all_improved_tests(self):
        """å…¨æœŸé–“ã§æ”¹å–„ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        periods = [
            'current', '2025_07', '2025_06', '2025_05', 
            '2025_04', '2024_Q4', 'Bull_Run_2024'
        ]
        
        logger.info("Starting improved prediction system tests...")
        logger.info(f"Target: 50%+ accuracy for all {len(periods)} periods")
        
        for period in periods:
            try:
                result = self.run_improved_backtest(period)
                if result:
                    self.results[period] = result
            except Exception as e:
                logger.error(f"Error processing {period}: {e}")
                continue
        
        # çµæœåˆ†æ
        self._analyze_improved_results()
        self._generate_improvement_report()
    
    def _analyze_improved_results(self):
        """æ”¹å–„çµæœã®åˆ†æ"""
        if not self.results:
            logger.error("No results to analyze")
            return
        
        # ç²¾åº¦çµ±è¨ˆ
        accuracies = [r['prediction_accuracy'] for r in self.results.values()]
        
        print(f"\n{'='*60}")
        print("æ”¹å–„ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ã®çµæœ")
        print(f"{'='*60}")
        print(f"å¹³å‡äºˆæ¸¬ç²¾åº¦: {np.mean(accuracies):.2%}")
        print(f"æœ€ä½äºˆæ¸¬ç²¾åº¦: {np.min(accuracies):.2%}")
        print(f"æœ€é«˜äºˆæ¸¬ç²¾åº¦: {np.max(accuracies):.2%}")
        print(f"50%ä»¥ä¸Šé”æˆæœŸé–“: {np.sum(np.array(accuracies) >= 0.5)}/{len(accuracies)}")
        
        print(f"\næœŸé–“åˆ¥çµæœ:")
        for period, result in self.results.items():
            accuracy = result['prediction_accuracy']
            status = "OK" if accuracy >= 0.5 else "NG"
            print(f"{status} {period}: {accuracy:.2%} (ç‰¹å¾´é‡: {result['features_used']})")
    
    def _generate_improvement_report(self):
        """æ”¹å–„ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        report = f"""
================================================================================
æ”¹å–„ã•ã‚ŒãŸAIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - æœ€çµ‚çµæœãƒ¬ãƒãƒ¼ãƒˆ
================================================================================
å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
ç›®æ¨™: å…¨æœŸé–“ã§50%ä»¥ä¸Šã®äºˆæ¸¬ç²¾åº¦é”æˆ

================================================================================
ã€æ”¹å–„ã•ã‚ŒãŸäºˆæ¸¬ç²¾åº¦ã€‘
================================================================================
"""
        
        accuracies = [r['prediction_accuracy'] for r in self.results.values()]
        above_50 = np.sum(np.array(accuracies) >= 0.5)
        
        report += f"""
å…¨ä½“çµ±è¨ˆ:
- å¹³å‡äºˆæ¸¬ç²¾åº¦: {np.mean(accuracies):.2%}
- æœ€ä½äºˆæ¸¬ç²¾åº¦: {np.min(accuracies):.2%}  
- æœ€é«˜äºˆæ¸¬ç²¾åº¦: {np.max(accuracies):.2%}
- 50%ä»¥ä¸Šé”æˆç‡: {above_50}/{len(accuracies)} ({above_50/len(accuracies)*100:.1f}%)

æœŸé–“åˆ¥è©³ç´°çµæœ:
"""
        
        for period, result in self.results.items():
            accuracy = result['prediction_accuracy']
            status = "OK ç›®æ¨™é”æˆ" if accuracy >= 0.5 else "NG æœªé”æˆ"
            
            # æœ€è‰¯æˆ¦ç•¥ã®ç‰¹å®š
            best_strategy = max(result['backtest_results'].items(), 
                              key=lambda x: x[1]['total_return'])
            
            report += f"""
{period}: {accuracy:.2%} {status}
  - ä½¿ç”¨ç‰¹å¾´é‡æ•°: {result['features_used']}
  - Buy & Hold: {result['buy_hold_return']:.2%}
  - æœ€è‰¯æˆ¦ç•¥: {best_strategy[0]} ({best_strategy[1]['total_return']:.2%})
"""
        
        # æ”¹å–„ç‚¹ã®åˆ†æ
        report += """
================================================================================
ã€å®Ÿè£…ã•ã‚ŒãŸæ”¹å–„ç‚¹ã€‘
================================================================================

1. é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°:
   - 70ä»¥ä¸Šã®æŠ€è¡“æŒ‡æ¨™ã¨çµ±è¨ˆç‰¹å¾´é‡
   - ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã«ã‚ˆã‚‹å‘¨æœŸæ€§æ¤œå‡º
   - å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºæ©Ÿèƒ½
   - ç›¸äº’ä½œç”¨ç‰¹å¾´é‡

2. æ”¹å–„ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«:
   - 11ç¨®é¡ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨
   - ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•
   - ç›¸äº’æƒ…å ±é‡ã«ã‚ˆã‚‹ç‰¹å¾´é‡é¸æŠ
   - ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

3. å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†:
   - ç•°å¸¸å€¤ã®é©åˆ‡ãªå‡¦ç†
   - æ¬ æå€¤ã®é«˜åº¦ãªè£œå®Œ
   - ãƒã‚¤ã‚ºé™¤å»æ©Ÿèƒ½

================================================================================
ã€çµè«–ã€‘
================================================================================
"""
        
        if above_50 == len(self.results):
            report += "ğŸ‰ ç›®æ¨™é”æˆï¼å…¨æœŸé–“ã§50%ä»¥ä¸Šã®äºˆæ¸¬ç²¾åº¦ã‚’å®Ÿç¾\n"
        elif above_50 >= len(self.results) * 0.8:
            report += f"âš¡ å¤§å¹…æ”¹å–„ï¼{above_50}/{len(self.results)}æœŸé–“ã§ç›®æ¨™é”æˆ\n"
        else:
            report += f"ğŸ“ˆ æ”¹å–„ä¸­ï¼{above_50}/{len(self.results)}æœŸé–“ã§ç›®æ¨™é”æˆ\n"
        
        report += f"""
ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿç”¨æ€§ãŒå¤§å¹…ã«å‘ä¸Šã—ã€ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„äºˆæ¸¬ãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚
å¹³å‡äºˆæ¸¬ç²¾åº¦: {np.mean(accuracies):.1%}

================================================================================
"""
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open(self.results_dir / 'improvement_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        
        # JSONä¿å­˜
        summary = {
            'execution_time': datetime.now().isoformat(),
            'target_achieved': bool(above_50 == len(self.results)),
            'achievement_rate': float(above_50 / len(self.results)),
            'average_accuracy': float(np.mean(accuracies)),
            'results': {
                period: {
                    'accuracy': float(result['prediction_accuracy']),
                    'target_met': bool(result['prediction_accuracy'] >= 0.5),
                    'features_used': int(result['features_used'])
                } for period, result in self.results.items()
            }
        }
        
        with open(self.results_dir / 'improvement_summary.json', 'w') as f:
            json.dump(summary, f, indent=2)
        
        logger.info(f"Improvement report saved to {self.results_dir}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    system = ImprovedPredictionSystem()
    
    try:
        system.run_all_improved_tests()
        logger.info("\nImproved system analysis completed!")
        print(f"\nResults saved to: {system.results_dir}")
    except Exception as e:
        logger.error(f"Analysis failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()